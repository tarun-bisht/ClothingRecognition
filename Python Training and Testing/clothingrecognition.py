# -*- coding: utf-8 -*-
##Written by : TARUN BISHT
"""ClothingRecognition.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vEh4ezJY0WIRzCepK7DmZAGAaB_tobX3

#Importing Libraries and Data
"""

import tensorflow as tf
import numpy as np
fashion_data=tf.keras.datasets.fashion_mnist
(x_train,y_train),(x_test,y_test)=fashion_data.load_data()

"""#All Clothings Labels Name Present in Dataset"""

clothings = ['T-shirt/Top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot']

"""#Visualizing"""

import matplotlib.pyplot as plt
for i in range(3):
    plt.imshow(x_train[i].reshape(28,28),cmap='binary')
    plt.show()
print(x_train[0].shape)

"""#Normalizing"""

x_train=tf.keras.utils.normalize(x_train)
x_test=tf.keras.utils.normalize(x_test)

"""#Creating Model"""

model=tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)),tf.keras.layers.Dense(128,tf.nn.relu),tf.keras.layers.Dense(28,tf.nn.relu),tf.keras.layers.Dense(10,tf.nn.softmax)])

"""#Compiling Model"""

model.compile(optimizer='adam',metrics=['accuracy'],loss='sparse_categorical_crossentropy')

"""#Training"""

model.fit(x_train,y_train,epochs=10)

"""#Evaluating"""

loss,accuracy=model.evaluate(x_test,y_test)
print("Loss:: ",loss)
print("Accuracy:: ",accuracy)

"""#Predicting"""

prediction=model.predict(x_test)
for i in range(100):
    plt.imshow(x_test[i].reshape(28,28),cmap='binary')
    print(prediction[i])
    prediction_label=np.argmax(prediction[i])
    print("Prediction Label= ",prediction_label)
    print("Predicted Object Name= ",clothings[prediction_label])
    plt.show()

"""#Downloading Model for Tensorflow js"""

!pip3 install tensorflowjs 
!mkdir model
model.save('model_clothing.h5')
!ls
!tensorflowjs_converter --input_format keras \conv.h5 \model
!zip -r model.zip model 
!ls -l
from google.colab import files
files.download('model.zip')

"""#Saving Model to Google Drive"""

# !pip install -U -q PyDrive
# from pydrive.auth import GoogleAuth
# from pydrive.drive import GoogleDrive
# from google.colab import auth
# from oauth2client.client import GoogleCredentials

# # 1. Authenticate and create the PyDrive client.
# auth.authenticate_user()
# gauth = GoogleAuth()
# gauth.credentials = GoogleCredentials.get_application_default()
# drive = GoogleDrive(gauth)

# # 2. Save Keras Model or weights on google drive
# # create on Colab directory  
# model_str = drive.CreateFile({'title' : 'convDigitRecognition.json'})
# model_str.SetContentFile('convDigitRecognition.json')
# model_file = drive.CreateFile({'title' : 'convDigitRecognition.h5'})
# model_file.SetContentFile('convDigitRecognition.h5')
# model_file.Upload()
# model_str.Upload()

# # download to google drive
# drive.CreateFile({'m_id': model_file.get('id'),'j_id': model_str.get('id')})

"""#Predicting for single output"""

input_img=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,0.20392156862745098,0,0,0,0,0,0,0,0,0,0,0,0,0,0.1843137254901961,0,0,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,0,0,0.8901960784313725,1,0.996078431372549,0,0,0,0.1568627450980392,1,1,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0.8745098039215686,1,1,1,1,1,1,1,0.00392156862745098,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,0.8745098039215686,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0.8941176470588236,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0.5058823529411764,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0.8274509803921568,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.6588235294117647,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.0392156862745098,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0.7647058823529411,1,0.996078431372549,0,0,0,0,0,0,0,0,1,0.9215686274509803,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,1,1,0,0,0,0,0,0,0,0,0.996078431372549,1,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,1,0.09019607843137255,1,0.7254901960784313,0,0,0,0,0,0,0,0.11764705882352941,1,0,0,0,0,0,0,0,0,0,0.45098039215686275,1,0,0,0,0,1,0,0.9647058823529412,1,0,0,0,0,0,0,0,0,1,0.5098039215686274,0,0,0,0,0,0,0,0,0.592156862745098,1,0,0,0,0,1,0,0,1,0.996078431372549,0,0,0,0,0,0,0,1,0.8549019607843137,0,0,0,0,0,0,0,0,0.9568627450980393,1,0,0,0,0.7686274509803922,1,0,0,0.011764705882352941,1,0,0,0,0,0,0,0,1,0.8941176470588236,0,0,0,0,0,0,0,0,1,1,0,0,0,0.7725490196078432,1,0,0,0,1,0.996078431372549,0,0,0,0,0,0,1,0.9254901960784314,0,0,0,0,0,0,0,0,1,0.1450980392156863,0,0,0,0.796078431372549,1,0,0,0,0.03137254901960784,1,0.9333333333333333,0,0,0,0,0,1,0.9294117647058824,0,0,0,0,0,0,0,0,1,0.10196078431372549,0,0,0,0.8784313725490196,1,0,0,0,0,0.996078431372549,1,0,0,0,0,0,1,0.9294117647058824,0,0,0,0,0,0,0,0,1,0.09411764705882353,0,0,0,0.8901960784313725,1,0,0,0,0,0.26666666666666666,1,0,0,0,0,0,1,0.8470588235294118,0,0,0,0,0,0,0,0,1,0.10196078431372549,0,0,0,0.8901960784313725,1,0,0,0,0,0,1,0.7568627450980392,0.7529411764705882,1,1,1,1,0.8588235294117647,0,0,0,0,0,0,0,0,1,0.09411764705882353,0,0,0.4980392156862745,1,1,0,0,0,0,0,1,1,1,1,1,1,1,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,0.023529411764705882,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]
img=np.array(input_img).reshape(1,28,28)
print(img.shape)
plt.imshow(img.reshape(28,28),cmap='binary')
plt.show()
pre=model.predict(img)
print(pre)
print(clothings[np.argmax(pre)])
